---
title: "Biostat 203B Homework 5"
subtitle: "Due March 20nd, 2025 @ 11:59PM"
author: Luke Hodges 906182810
format:
  html: 
    theme: cosmo
    embed-resources: true
    number-sections: false
    toc: true
    toc-depth: 4
    toc-location: left
    code-fold: false
    link-external-icon: true
    link-external-newwindow: true
---
## Loading in the necessary libraries and data file
```{r}
# Load required libraries
library(tidyverse)
library(tidymodels)
library(glmnet)
library(GGally)
library(ranger)
library(gtsummary)
library(stacks)
library(keras)
library(pROC)
library(xgboost)
library(caret)
library(vip)

# Load the MIMIC-IV dataset

mimic_icu_cohort <- readRDS("../homework4/mimiciv_shiny/mimic_icu_cohort.rds")

mimic_icu_cohort <- mimic_icu_cohort |>
  arrange(subject_id, hadm_id, stay_id)

mimic_icu_cohort <- mimic_icu_cohort |>
  mutate(los_long = los >= 2)

mimic_icu_cohort$los_long <- as.factor(mimic_icu_cohort$los_long)

```

## Logistic Regression

**Data preprocessing and feature engineering.**

```{r}

#Remove ID Columns and then Select the Predictors
icu_data <- mimic_icu_cohort %>%
  select(subject_id, hadm_id, stay_id, los_long, first_careunit, gender, 
         age_intime, marital_status, race, Heart_Rate, DiaBP, SysBP, 
         Respiratory_Rate, Temp, Creatinine, Potassium, Chloride, Bicarbonate, 
         Hematocrit, WBC, Sodium)
    
icu_data <- icu_data %>%
  arrange(subject_id, hadm_id, stay_id)


##We need to make sure that los_long is a factor as we got this as an error
icu_data$los_long <- as.factor(icu_data$los_long)

##Now we need to remove all the NA values
icu_data <- icu_data %>%
  drop_na(first_careunit, gender, age_intime, marital_status, race, Heart_Rate, 
          DiaBP, SysBP, Respiratory_Rate, Temp, Creatinine, Potassium, 
          Chloride, Bicarbonate, Hematocrit, WBC, Sodium)

##We can check to see if there are any NAs here
colSums(is.na(icu_data))

```

**Partition data into 50% training set and 50% test set. Stratify partitioning according to los_long. For grading purpose, sort the data by subject_id, hadm_id, and stay_id and use the seed 203 for the initial data split.**

```{r}
set.seed(203)

# Stratified split by los_long
icu_split <- initial_split(
  icu_data,
  strata = los_long,
  prop = 0.5
)

icu_train <- training(icu_split)
icu_test <- testing(icu_split)

head(icu_train)
head(icu_test)

##Now, let us make the logit_recipe for the logistic regression model

logit_recipe <- recipe(
  los_long ~ first_careunit + gender + age_intime + marital_status + race +
    Heart_Rate + DiaBP + SysBP + Respiratory_Rate + Temp +
    Creatinine + Potassium + Chloride + Bicarbonate + Hematocrit + WBC + Sodium,
  data = icu_train
) %>%
  step_impute_median(all_numeric_predictors()) %>%
  step_impute_mode(all_nominal_predictors()) %>%
  step_novel(all_nominal_predictors()) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_zv(all_predictors()) %>%
  step_normalize(all_numeric_predictors())

```

**Train and tune the models using the training set.**

```{r}
logit_mod <- logistic_reg(
  penalty = tune(),
  mixture = tune() 
) %>%
  set_engine("glmnet", standardize = FALSE) %>%
  set_mode("classification") %>%
  print()

logit_wf <- workflow() %>%
  add_recipe(logit_recipe) %>%
  add_model(logit_mod) %>%
  print()
```

```{r}

param_grid <- grid_regular(
  penalty(range = c(-6, 3)),   # log10 scale
  mixture(),
  levels = c(100, 5)
) %>% 
  print()

```

```{r}

##We are going to use a v = 3 since my laptop takes a while to load v = 3. We need to make sure this stays consistent for the next few models

set.seed(203)
cv_folds <- vfold_cv(icu_train, v = 3)

cv_folds

```

```{r}

logit_tune <- tune_grid(
  object = logit_wf, 
  resamples = cv_folds, 
  grid = param_grid, 
  metrics = metric_set(roc_auc, accuracy),
  control = control_stack_grid()
)

```

```{r}
logit_tune
```

```{r}
logit_tune_roc <- logit_tune |>
  collect_metrics() |>
  filter(.metric == "roc_auc")

logit_tune_roc

logit_tune_roc |>
  ggplot(aes(x = penalty, y = mean, color = factor(mixture))) +
  geom_point() +
  geom_line() +
  labs(
    title = "ROC AUC by Penalty and Mixture (Elastic Net)",
    x = "Penalty (Lambda)",
    y = "Mean ROC AUC",
    color = "Mixture (Alpha)"
  ) +
  scale_x_log10()
```

**Compare model classification performance on the test set. Report both the area under ROC curve and accuracy for each machine learning algorithm and the model stacking. Interpret the results. What are the most important features in predicting long ICU stays?**

```{r}
show_best(logit_tune, metric = "roc_auc")

best_logit <- select_best(logit_tune, metric = "roc_auc")
best_logit

final_logit_wf <- finalize_workflow(
  logit_wf,
  best_logit
)

final_logit_fit <- last_fit(
  final_logit_wf,
  split = icu_split
)

# Collect metrics on the test set
collect_metrics(final_logit_fit)

```

```{r}
predictions <- collect_predictions(final_logit_fit)
conf_mat(predictions, truth = los_long, estimate = .pred_class)

final_model <- extract_fit_parsnip(final_logit_fit$.workflow[[1]])
tidy(final_model) %>%
  arrange(desc(estimate)) %>%
  print(n = Inf)
```

**The Accuracy is 0.579; the ROC AUC is 0.609; and the Brier score is 0.241. Regrading accuracy, this means that 57.9% of the time, the model correctly predicts whether or not a patient has a long or short ICU stay based on the features examined. This means that this is better than just randomly guessing, which would give more of a 50-50 split.**

**The ROC AUC indicates that the model is able to distinguish ICU stays between long and short in a modest way.**

**The Brier score being low is good -- however, there is room for improvement as it can be lower**

**The Top Five Most Important Features Are: Heart Rate (+0.174), Respiratory Rate (+0.128), Age (+0.124), Neuro Intermediate Care Service (+0.164). In other words, those with a higher heart_rate, respiratory rate, age, and also placed into the neuro intermediate care service had a higher chance of having a longer ICU stay. This makes sense considering that higher_heart rate and respiratory rates are a sign of distress, while older age is linked to frailty and needs more attention than individuals that are younger**


## Random Forest

**Data Preprocessing and engineering**

```{r}

#Remove ID Columns and then Select the Predictors
icu_data <- mimic_icu_cohort %>%
  select(subject_id, hadm_id, stay_id, los_long, first_careunit, gender, 
         age_intime, marital_status, race, Heart_Rate, DiaBP, SysBP, 
         Respiratory_Rate, Temp, Creatinine, Potassium, Chloride, Bicarbonate, 
         Hematocrit, WBC, Sodium)
    
icu_data <- icu_data %>%
  arrange(subject_id, hadm_id, stay_id)


##We need to make sure that los_long is a factor as we got this as an error
icu_data$los_long <- as.factor(icu_data$los_long)

##Now we need to remove all the NA values
icu_data <- icu_data %>%
  drop_na(first_careunit, gender, age_intime, marital_status, race, Heart_Rate, 
          DiaBP, SysBP, Respiratory_Rate, Temp, Creatinine, Potassium, 
          Chloride, Bicarbonate, Hematocrit, WBC, Sodium)

##We can check to see if there are any NAs here
colSums(is.na(icu_data))
```

**Partition data into 50% training set and 50% test set. Stratify partitioning according to los_long. For grading purpose, sort the data by subject_id, hadm_id, and stay_id and use the seed 203 for the initial data split.**

```{r}
set.seed(203)

# Stratified split by los_long
icu_split <- initial_split(
  icu_data,
  strata = los_long,
  prop = 0.5
)

icu_train <- training(icu_split)
icu_test <- testing(icu_split)

head(icu_train)
head(icu_test)

```

**Train and tune the models using the training set.**

```{r}
rf_recipe <- recipe(
  los_long ~ first_careunit + gender + age_intime + marital_status + race +
    Heart_Rate + DiaBP + SysBP + Respiratory_Rate + Temp +
    Creatinine + Potassium + Chloride + Bicarbonate + Hematocrit + WBC + Sodium,
  data = icu_train
) %>%
  step_impute_median(all_numeric_predictors()) %>%
  step_impute_mode(all_nominal_predictors()) %>%
  step_novel(all_nominal_predictors()) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_zv(all_predictors())
```

```{r}
rf_mod <- rand_forest(
  mode = "classification",
  mtry = tune(),
  trees = tune()) %>%
  set_engine("ranger", importance = "impurity") %>%
  set_mode("classification") %>%
  print()
```

```{r}
rf_wf <- workflow() %>%
  add_recipe(rf_recipe) %>% 
  add_model(rf_mod)
```

```{r}

rf_params <- hardhat::extract_parameter_set_dials(rf_mod)

# Define a smaller tuning grid for faster search

rf_grid <- grid_regular(
  trees(range = c(100L, 300L)),
  mtry(range = c(3, 10)),
  levels = c(5, 5)
)

```

```{r}
set.seed(203)

##we are going to keep at it 3 for consistency

cv_folds <- vfold_cv(icu_train, v = 3)

rf_tune <- tune_grid(
  rf_wf,
  resamples = cv_folds,
  grid = rf_grid,
  metrics = metric_set(roc_auc, accuracy),
  control = control_stack_grid()
)
```

```{r}
collect_metrics(rf_tune)

# Plot ROC AUC vs mtry and min_n

rf_tune %>%
  collect_metrics() |>
  print(width = Inf) |>
  filter(.metric == "roc_auc") |>
  ggplot(mapping = aes(x = trees, y = mean, color = factor(mtry))) +
  geom_point() +
  labs(
    title = "Random Forest ROC AUC",
    x = "mtry",
    color = "min_n"
  )
```

```{r}

# Select best hyperparameters (corrected)
best_rf <- select_best(rf_tune, metric = "roc_auc")

rf_tune |>
  show_best(metric = "roc_auc")

```

```{r}

# Finalize the workflow with the best hyperparameters
final_rf_wf <- finalize_workflow(rf_wf, best_rf)

# Fit the final model on the training set and evaluate on the test set
final_rf_fit <- final_rf_wf |>
  last_fit(icu_split)

final_rf_fit

# Collect metrics on the test set
collect_metrics(final_rf_fit)

# Generate predictions on the test set
predictions_rf <- collect_predictions(final_rf_fit)
conf_mat(predictions_rf, truth = los_long, estimate = .pred_class)
```

```{r}
final_modelrf <- extract_fit_parsnip(final_rf_fit$.workflow[[1]])
# View variable importance in a table
importance_df <- final_modelrf$fit$variable.importance %>%
  enframe(name = "feature", value = "importance") %>%
  arrange(desc(importance))

# Show all features and their importance
print(importance_df, n = Inf)

```

## XGBoost

**Data Preprocessing and engineering**

```{r}

#Remove ID Columns and then Select the Predictors
icu_data <- mimic_icu_cohort %>%
  select(subject_id, hadm_id, stay_id, los_long, first_careunit, gender, 
         age_intime, marital_status, race, Heart_Rate, DiaBP, SysBP, 
         Respiratory_Rate, Temp, Creatinine, Potassium, Chloride, Bicarbonate, 
         Hematocrit, WBC, Sodium)
    
icu_data <- icu_data %>%
  arrange(subject_id, hadm_id, stay_id)


##We need to make sure that los_long is a factor as we got this as an error
icu_data$los_long <- as.factor(icu_data$los_long)

##Now we need to remove all the NA values
icu_data <- icu_data %>%
  drop_na(first_careunit, gender, age_intime, marital_status, race, Heart_Rate, 
          DiaBP, SysBP, Respiratory_Rate, Temp, Creatinine, Potassium, 
          Chloride, Bicarbonate, Hematocrit, WBC, Sodium)

##We can check to see if there are any NAs here
colSums(is.na(icu_data))
```

**Partition data into 50% training set and 50% test set. Stratify partitioning according to los_long. For grading purpose, sort the data by subject_id, hadm_id, and stay_id and use the seed 203 for the initial data split.**

```{r}
set.seed(203)

# Stratified split by los_long
icu_split <- initial_split(
  icu_data,
  strata = los_long,
  prop = 0.5
)

icu_train <- training(icu_split)
icu_test <- testing(icu_split)

head(icu_train)
head(icu_test)

```

**Train and Tune the Models Using the Training Set**

```{r}
XGBoostRecipe <- recipe(
  los_long ~ first_careunit + gender + age_intime + marital_status + race +
    Heart_Rate + DiaBP + SysBP + Respiratory_Rate + Temp +
    Creatinine + Potassium + Chloride + Bicarbonate + Hematocrit + WBC + Sodium,
  data = icu_train
) %>%
  step_impute_mean(all_numeric_predictors()) %>%
  step_impute_mode(all_nominal_predictors()) %>%
  step_novel(all_nominal_predictors()) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_zv(all_predictors())
```

**Model specificaiton process with tuning paramters**

```{r}
xgb_mod <- boost_tree(
  mode = "classification",
  trees = tune(),
  tree_depth = tune(),
  learn_rate = tune()) %>%
  set_engine("xgboost") %>%
  set_mode("classification")
```

**Now let us bundle the recipe we did wih our model into a workflow**

```{r}
xgb_wf <- workflow() |>
  add_recipe(XGBoostRecipe) |>
  add_model(xgb_mod)
```

**Now we will define the grid for tuning**

```{r}

xgb_params <- hardhat::extract_parameter_set_dials(xgb_mod)

xgb_grid <- grid_regular(
  trees(range = c(100L, 300L)),
  tree_depth(range = c(3L, 10L)),
  learn_rate(range = c(-3,-1)),
  levels = c(5, 5, 3)
)
```

**Now we will perform the tuning**

```{r}
set.seed(203)

xgbcv_folds <- vfold_cv(icu_train, v = 3)

xgb_fit <- tune_grid(
  xgb_wf,
  resamples = xgbcv_folds,
  grid = xgb_grid,
  metrics = metric_set(roc_auc, accuracy),
  control = control_stack_grid()
)
```

```{r}
best_xgb <- xgb_fit |>
  select_best(metric = "roc_auc")
```

```{r}
final_xgb_wf <- xgb_wf |>
  finalize_workflow(best_xgb)

final_xgb_fit <- final_xgb_wf |>
  last_fit(icu_split)

final_xgb_fit |>
  collect_metrics()

```

```{r}

predictions_xgb <- collect_predictions(final_xgb_fit)
conf_mat(predictions_xgb, truth = los_long, estimate = .pred_class)

final_modelxgb <- extract_fit_parsnip(final_xgb_fit$.workflow[[1]])

importance_df_xgb <- xgb.importance(model = final_modelxgb$fit) %>%
  as_tibble() %>%
  arrange(desc(Gain))

# Show all features and their importance (by Gain)
print(importance_df_xgb, n = Inf)

```

## Model Stacking Log. Regression, Random Forest, and XGBoost

**Data Preprocessing and engineering**

```{r}
set.seed(203)

# Stratified split by los_long
icu_split <- initial_split(
  icu_data,
  strata = los_long,
  prop = 0.5
)

icu_train <- training(icu_split)
icu_test <- testing(icu_split)

head(icu_train)
head(icu_test)

##Now, let us make the logit_recipe for the logistic regression model

modelstacking <- recipe(
  los_long ~ first_careunit + gender + age_intime + marital_status + race +
    Heart_Rate + DiaBP + SysBP + Respiratory_Rate + Temp +
    Creatinine + Potassium + Chloride + Bicarbonate + Hematocrit + WBC + Sodium,
  data = icu_train
) %>%
  step_impute_median(all_numeric_predictors()) %>%
  step_impute_mode(all_nominal_predictors()) %>%
  step_novel(all_nominal_predictors()) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_zv(all_predictors()) %>%
  step_normalize(all_numeric_predictors())
```

```{r}
set.seed(203)
foldsSTACK <- vfold_cv(icu_train, v = 3)
```

## Final Model Stacking: 

```{r}
icu_stack <- 
  stacks() %>%
  add_candidates(logit_tune) %>%
  add_candidates(rf_tune) %>%
  add_candidates(xgb_fit) %>%
  blend_predictions(
    penalty = 10^(-2:0),
    metrics = c("roc_auc", "accuracy")
  ) |>
  fit_members()

icu_stack

```

```{r}

autoplot(icu_stack)

```

```{r}

autoplot(icu_stack, type = "members")

```

```{r}

autoplot(icu_stack, type = "weights")

```

```{r}

collect_parameters(icu_stack, "rf_tune") |>
  print(n = Inf)
```

```{r}
collect_parameters(icu_stack, "logit_tuneSTACK") |>
  print(n = Inf)
```

```{r}
collect_parameters(icu_stack, "xgb_tuneSTACK") |>
  print(n = Inf)
```

```{r}
icu_stack_pred <- icu_test %>%
  bind_cols(predict(icu_stack, ., type = "prob")) %>%
  print(width = Inf)
```

```{r}
yardstick::roc_auc(
  icu_stack_pred,
  truth = los_long,
  .pred_TRUE
)
```

```{r}
icu_pred <- 
  icu_test |>
  select(los_long) |>
  bind_cols(
    predict(
      icu_stack,
      icu_test,
      type = "class",
      members = TRUE
    )
  )
  print(width = Inf)

```

```{r}

icu_pred_accuracy <- 
  map(
    colnames(icu_pred)[-1],
    ~mean(icu_pred$los_long == pull(icu_pred, .x))
  ) |>
  set_names(colnames(icu_pred)[-1]) |>
  as_tibble() |>
  pivot_longer(cols = everything(), names_to = "model", values_to = "accuracy")

icu_pred_accuracy

```
