---
title: "Biostat 203B Homework 5"
subtitle: "Due March 22nd, 2025 @ 11:59PM"
author: Luke Hodges 906182810
format:
  html: 
    theme: cosmo
    embed-resources: true
    number-sections: false
    toc: true
    toc-depth: 4
    toc-location: left
    code-fold: false
    link-external-icon: true
    link-external-newwindow: true
---
## Loading in the necessary libraries and data file
```{r}
# Load required libraries
library(tidyverse)
library(tidymodels)
library(glmnet)
library(GGally)
library(ranger)
library(gtsummary)
library(pROC)
library(xgboost)
library(caret)
library(vip)

# Load the MIMIC-IV dataset

mimic_icu_cohort <- readRDS("../homework4/mimiciv_shiny/mimic_icu_cohort.rds")

mimic_icu_cohort <- mimic_icu_cohort |>
  arrange(subject_id, hadm_id, stay_id)

mimic_icu_cohort <- mimic_icu_cohort |>
  mutate(los_long = los >= 2)

mimic_icu_cohort$los_long <- as.factor(mimic_icu_cohort$los_long)

```

## Logistic Regression

**Data preprocessing and feature engineering.**

```{r}

#Remove ID Columns and then Select the Predictors
icu_data <- mimic_icu_cohort %>%
  select(subject_id, hadm_id, stay_id, los_long, first_careunit, gender, 
         age_intime, marital_status, race, Heart_Rate, DiaBP, SysBP, 
         Respiratory_Rate, Temp, Creatinine, Potassium, Chloride, Bicarbonate, 
         Hematocrit, WBC, Sodium)
    
icu_data <- icu_data %>%
  arrange(subject_id, hadm_id, stay_id)


##We need to make sure that los_long is a factor as we got this as an error
icu_data$los_long <- as.factor(icu_data$los_long)

##Now we need to remove all the NA values
icu_data <- icu_data %>%
  drop_na(first_careunit, gender, age_intime, marital_status, race, Heart_Rate, 
          DiaBP, SysBP, Respiratory_Rate, Temp, Creatinine, Potassium, 
          Chloride, Bicarbonate, Hematocrit, WBC, Sodium)

##We can check to see if there are any NAs here
colSums(is.na(icu_data))

```

**Partition data into 50% training set and 50% test set. Stratify partitioning according to los_long. For grading purpose, sort the data by subject_id, hadm_id, and stay_id and use the seed 203 for the initial data split.**

```{r}
set.seed(203)

# Stratified split by los_long
icu_split <- initial_split(
  icu_data,
  strata = los_long,
  prop = 0.5
)

icu_train <- training(icu_split)
icu_test <- testing(icu_split)

head(icu_train)
head(icu_test)

##Now, let us make the logit_recipe for the logistic regression model

logit_recipe <- recipe(
  los_long ~ first_careunit + gender + age_intime + marital_status + race +
    Heart_Rate + DiaBP + SysBP + Respiratory_Rate + Temp +
    Creatinine + Potassium + Chloride + Bicarbonate + Hematocrit + WBC + Sodium,
  data = icu_train
) %>%
  step_impute_median(all_numeric_predictors()) %>%
  step_impute_mode(all_nominal_predictors()) %>%
  step_novel(all_nominal_predictors()) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_zv(all_predictors()) %>%
  step_normalize(all_numeric_predictors())

```

**Train and tune the models using the training set.**

```{r}
logit_mod <- logistic_reg(
  penalty = tune(),
  mixture = tune() 
) %>%
  set_engine("glmnet", standardize = FALSE) %>%
  set_mode("classification") %>%
  print()

logit_wf <- workflow() %>%
  add_recipe(logit_recipe) %>%
  add_model(logit_mod) %>%
  print()
```

```{r}

param_grid <- grid_regular(
  penalty(range = c(-6, 3)),   # log10 scale
  mixture(),
  levels = c(100, 5)
) %>% 
  print()

```

```{r}

##We are going to use a v = 3 since my laptop takes a while to load v = 3. We need to make sure this stays consistent for the next few models

set.seed(203)
cv_folds <- vfold_cv(icu_train, v = 3)

cv_folds

```

```{r}

logit_tune <- tune_grid(
  object = logit_wf, 
  resamples = cv_folds, 
  grid = param_grid, 
  metrics = metric_set(roc_auc, accuracy)
)

```

```{r}
logit_tune
```

```{r}
logit_tune_roc <- logit_tune |>
  collect_metrics() |>
  filter(.metric == "roc_auc")

logit_tune_roc

logit_tune_roc |>
  ggplot(aes(x = penalty, y = mean, color = factor(mixture))) +
  geom_point() +
  geom_line() +
  labs(
    title = "ROC AUC by Penalty and Mixture (Elastic Net)",
    x = "Penalty (Lambda)",
    y = "Mean ROC AUC",
    color = "Mixture (Alpha)"
  ) +
  scale_x_log10()
```

**Compare model classification performance on the test set. Report both the area under ROC curve and accuracy for each machine learning algorithm and the model stacking. Interpret the results. What are the most important features in predicting long ICU stays?**

```{r}
show_best(logit_tune, metric = "roc_auc")

best_logit <- select_best(logit_tune, metric = "roc_auc")
best_logit

final_logit_wf <- finalize_workflow(
  logit_wf,
  best_logit
)

final_logit_fit <- last_fit(
  final_logit_wf,
  split = icu_split
)

# Collect metrics on the test set
collect_metrics(final_logit_fit)

```

```{r}
predictions <- collect_predictions(final_logit_fit)
conf_mat(predictions, truth = los_long, estimate = .pred_class)

final_model <- extract_fit_parsnip(final_logit_fit$.workflow[[1]])
tidy(final_model) %>%
  print(n = Inf)
```

**The Accuracy is 0.579; the ROC AUC is 0.609; and the Brier score is 0.241. Regrading accuracy, this means that 57.9% of the time, the model correctly predicts whether or not a patient has a long or short ICU stay based on the features examined. This means that this is better than just randomly guessing, which would give more of a 50-50 split.**

**The ROC AUC indicates that the model is able to distinguish ICU stays between long and short in a modest way.**

**The Brier score being low is good -- however, there is room for improvement as it can be lower**

**The Top Five Most Important Features Are: Heart Rate (+0.174), Respiratory Rate (+0.128), Age (+0.124), Creatinine (+0.0576), and SysBP (-2.38). In other words, those with a higher heart and respiratory rate, those who are older, and have more craetinine, and lower SysBP are more likely to have a longer ICU stay.**


## Random Forest

```{r}
rf_recipe <- recipe(
  los_long ~ first_careunit + gender + age_intime + marital_status + race +
    Heart_Rate + DiaBP + SysBP + Respiratory_Rate + Temp +
    Creatinine + Potassium + Chloride + Bicarbonate + Hematocrit + WBC + Sodium,
  data = icu_train
) %>%
  # Impute missing numeric values with median
  step_impute_median(all_numeric_predictors()) %>%
  # Impute categorical (nominal) with mode
  step_impute_mode(all_nominal_predictors()) %>%
  # Dummy encoding for categorical variables
  step_novel(all_nominal_predictors()) %>%
  step_dummy(all_nominal_predictors()) %>%
  # Remove zero variance predictors
  step_zv(all_predictors())
  # Normalize numeric predictors
```

```{r}

rf_mod <- rand_forest(
  mode = "classification",
  mtry = tune(),           # number of predictors at each split (tuned)
  trees = tune()              # fewer trees for speed
) %>%
  set_engine("ranger") %>%
  print()
```

```{r}
rf_wf <- workflow() %>%
  add_recipe(logit_recipe) %>%   # reuse the recipe from logistic regression
  add_model(rf_mod)
```

```{r}

rf_params <- hardhat::extract_parameter_set_dials(rf_mod)

# Define a smaller tuning grid for faster search
rf_grid <- grid_regular(
  trees(range = c(100L, 300L)),
  mtry(range = c(3, 10)),      # adjust based on # of predictors (we have ~18)
  levels = c(5, 5)                   # keeps grid small for speed
)

```

```{r}

set.seed(203)
cv_folds <- vfold_cv(icu_train, v = 5)

rf_tune <- tune_grid(
  rf_wf,
  resamples = cv_folds,
  grid = rf_grid,
  metrics = metric_set(roc_auc, accuracy),
)
```

```{r}
collect_metrics(rf_tune)

# Plot ROC AUC vs mtry and min_n
rf_tune %>%
  collect_metrics() %>%
  filter(.metric == "roc_auc") %>%
  ggplot(aes(x = mtry, y = mean, color = factor(min_n))) +
  geom_point() +
  geom_line() +
  labs(
    title = "Random Forest ROC AUC",
    x = "mtry",
    color = "min_n"
  )
```

```{r}

# Select best hyperparameters (corrected)
best_rf <- select_best(rf_tune, metric = "roc_auc")

rf_tune |>
  show_best(metric = "roc_auc")

```

```{r}

# Finalize the workflow with the best hyperparameters
final_rf_wf <- finalize_workflow(rf_wf, best_rf)

# Fit the final model on the training set and evaluate on the test set
final_rf_fit <- final_rf_wf |>
  last_fit(icu_split)

final_rf_fit

# Collect metrics on the test set
collect_metrics(final_rf_fit)

# Generate predictions on the test set
predictions_rf <- collect_predictions(final_rf_fit)

```

## XGBoost

```{r}
XGBoostRecipe <- recipe(
  los_long ~ first_careunit + gender + age_intime + marital_status + race +
    Heart_Rate + DiaBP + SysBP + Respiratory_Rate + Temp +
    Creatinine + Potassium + Chloride + Bicarbonate + Hematocrit + WBC + Sodium,
  data = icu_train
) %>%
  # Impute missing numeric values with median
  step_impute_mean(all_numeric_predictors()) %>%
  # Impute categorical (nominal) with mode
  step_impute_mode(all_nominal_predictors()) %>%
  # Dummy encoding for categorical variables
  step_novel(all_nominal_predictors()) %>%
  step_dummy(all_nominal_predictors()) %>%
  # Remove zero variance predictors
  step_zv(all_predictors())
  # Normalize numeric predictors
```

**MOdel specificaiton process with tuning paramters**

```{r}
xgb_mod <- boost_tree(
  mode = "classification",
  trees = 1000,
  tree_depth = tune(),
  learn_rate = tune()
) |>
  set_engine("xgboost")
```

**Now let us bundle the recipe we did wih our model into a workflow**

```{r}
xgb_wf <- workflow() |>
  add_recipe(XGBoostRecipe) |>
  add_model(xgb_mod)
```

**Now we will define the grid for tuning**

```{r}
param_grid <- grid_regular(
  tree_depth(range = c(2L, 4L)),
  learn_rate(range = c(-5, 0), trans = log10_trans()),
  levels = c(3,5)
)
```

**Now we will perform the tuning**

```{r}
set.seed(203)

icu_folds <- vfold_cv(icu_train, v = 5)

xgb_fit <- tune_grid(
  xgb_wf,
  resamples = icu_folds,
  grid = param_grid,
  metrics = metric_set(roc_auc, accuracy)
)
```

